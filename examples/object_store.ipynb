{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as PythonPath\n",
    "\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.fs as fs\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from object_store.arrow import ArrowFileSystemHandler\n",
    "\n",
    "table = pa.table({\"a\": range(10), \"b\": np.random.randn(10), \"c\": [1, 2] * 5})\n",
    "\n",
    "base = PythonPath.cwd()\n",
    "store = fs.PyFileSystem(ArrowFileSystemHandler(str(base.absolute())))\n",
    "arrow_fs = fs.SubTreeFileSystem(str(base.absolute()), fs.LocalFileSystem())\n",
    "\n",
    "pq.write_table(table.slice(0, 5), \"data/data1.parquet\", filesystem=store)\n",
    "pq.write_table(table.slice(5, 10), \"data/data2.parquet\", filesystem=store)\n",
    "\n",
    "dataset = ds.dataset(\"data\", format=\"parquet\", filesystem=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as PythonPath\n",
    "\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.fs as fs\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from object_store.arrow import ArrowFileSystemHandler\n",
    "\n",
    "table = pa.table({\"a\": range(10), \"b\": np.random.randn(10), \"c\": [1, 2] * 5})\n",
    "\n",
    "base = PythonPath.cwd()\n",
    "store = ArrowFileSystemHandler(str(base.absolute()))\n",
    "\n",
    "import pickle\n",
    "\n",
    "with PythonPath(\"asd.pkl\").open(\"wb\") as handle:\n",
    "    pickle.dump(store, handle)\n",
    "\n",
    "with PythonPath(\"asd.pkl\").open(\"rb\") as handle:\n",
    "    store_pkl = pickle.load(handle)\n",
    "\n",
    "store_pkl.get_file_info([\"asd.pkl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_store import ObjectMeta, ObjectStore\n",
    "\n",
    "# we use an in-memory store for demonstration purposes.\n",
    "# data will not be persisted and is not shared across store instances\n",
    "store = ObjectStore(\"memory://\")\n",
    "\n",
    "store.put(\"data\", b\"some data\")\n",
    "\n",
    "data = store.get(\"data\")\n",
    "assert data == b\"some data\"\n",
    "\n",
    "blobs = store.list()\n",
    "\n",
    "meta: ObjectMeta = store.head(\"data\")\n",
    "\n",
    "range = store.get_range(\"data\", start=0, length=4)\n",
    "assert range == b\"some\"\n",
    "\n",
    "store.copy(\"data\", \"copied\")\n",
    "copied = store.get(\"copied\")\n",
    "assert copied == data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "results = con.execute(\"SELECT * FROM dataset WHERE c = 2\").arrow()\n",
    "\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_paths = []\n",
    "\n",
    "\n",
    "def file_visitor(written_file):\n",
    "    visited_paths.append(written_file)\n",
    "\n",
    "\n",
    "partitioning = ds.partitioning(pa.schema([(\"c\", pa.int64())]), flavor=\"hive\")\n",
    "ds.write_dataset(\n",
    "    table,\n",
    "    \"partitioned\",\n",
    "    partitioning=partitioning,\n",
    "    format=\"parquet\",\n",
    "    filesystem=store,\n",
    "    file_visitor=file_visitor,\n",
    ")\n",
    "\n",
    "len(visited_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning = ds.partitioning(pa.schema([(\"c\", pa.int64())]), flavor=\"hive\")\n",
    "dataset_part = ds.dataset(\"/partitioned\", format=\"parquet\", filesystem=store, partitioning=partitioning)\n",
    "dataset_part.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_store import ObjectStore\n",
    "\n",
    "store = ObjectStore(\"az://delta-rs\", options={\"account_name\": \"mlfusiondev\", \"use_azure_cli\": \"true\"})\n",
    "\n",
    "store.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pyarrow.fs as pa_fs\n",
    "\n",
    "from object_store import ClientOptions\n",
    "from object_store.arrow import ArrowFileSystemHandler\n",
    "\n",
    "storage_options = {\n",
    "    \"account_name\": os.environ[\"AZURE_STORAGE_ACCOUNT_NAME\"],\n",
    "    \"account_key\": os.environ[\"AZURE_STORAGE_ACCOUNT_KEY\"],\n",
    "}\n",
    "\n",
    "filesystem = pa_fs.PyFileSystem(ArrowFileSystemHandler(\"adl://simple\", storage_options, ClientOptions()))\n",
    "filesystem.get_file_info([\"part-00000-a72b1fb3-f2df-41fe-a8f0-e65b746382dd-c000.snappy.parquet\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d6ce819d12cb3dc1d584870253e9f5e189fd2e2773823a6ff4f2c218d69ebab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
